services:
  app:
    image: ${APP_IMAGE:-1001-stories-app:latest}
    build:
      context: .
      dockerfile: Dockerfile
      args:
        - BUILDKIT_INLINE_CACHE=1
    container_name: 1001-stories-app
    restart: unless-stopped
    security_opt:
      - no-new-privileges:true
    read_only: true
    tmpfs:
      - /tmp:noexec,nosuid,size=100m
      - /app/tmp:noexec,nosuid,size=100m
    ports:
      - "3000:3000"
    env_file:
      - .env.production
    environment:
      - NODE_ENV=production
    volumes:
      - ./uploads:/app/uploads:rw
      - ./prisma:/app/prisma:ro
      - ./public/books:/app/public/books:ro
      - ./public/generated-images:/app/public/generated-images:rw
    networks:
      - app-network
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.25'
          memory: 256M
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:3000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  postgres:
    image: postgres:15-alpine
    container_name: 1001-stories-postgres
    restart: unless-stopped
    env_file:
      - .env.production
    # ports:
      # - "5432:5432"  # Removed for production security - use pgbouncer internally
    environment:
      - POSTGRES_USER=stories_user
      - POSTGRES_PASSWORD=${DB_PASSWORD}
      - POSTGRES_DB=stories_db
      - PGDATA=/var/lib/postgresql/data/pgdata
      # Performance tuning
      - POSTGRES_SHARED_PRELOAD_LIBRARIES=pg_stat_statements
      - POSTGRES_INITDB_ARGS=--data-checksums
    volumes:
      - postgres_data:/var/lib/postgresql/data:rw
      - ./postgres/postgresql.conf:/etc/postgresql/postgresql.conf:ro
      - ./postgres/init-scripts:/docker-entrypoint-initdb.d:ro
    networks:
      - app-network
    deploy:
      resources:
        limits:
          cpus: '0.75'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 256M
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U stories_user -d stories_db"]
      interval: 10s
      timeout: 5s
      retries: 5
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    command: [
      "postgres",
      "-c", "config_file=/etc/postgresql/postgresql.conf",
      "-c", "log_statement=all",
      "-c", "log_destination=stderr",
      "-c", "logging_collector=off"
    ]

  redis:
    image: redis:7-alpine
    container_name: 1001-stories-redis
    restart: unless-stopped
    env_file:
      - .env.production
    command: [
      "redis-server",
      "--appendonly", "yes",
      "--requirepass", "${REDIS_PASSWORD}",
      "--maxmemory", "256mb",
      "--maxmemory-policy", "allkeys-lru",
      "--save", "900", "1",
      "--save", "300", "10",
      "--save", "60", "10000",
      "--tcp-keepalive", "300",
      "--timeout", "0"
    ]
    volumes:
      - redis_data:/data:rw
    # ports:
      # - "6379:6379"  # Removed for production security - Redis accessible internally only
    networks:
      - app-network
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 256M
        reservations:
          cpus: '0.1'
          memory: 64M
    healthcheck:
      test: ["CMD", "redis-cli", "--raw", "incr", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    logging:
      driver: "json-file"
      options:
        max-size: "5m"
        max-file: "2"

  nginx:
    image: nginx:alpine
    container_name: 1001-stories-nginx
    restart: unless-stopped
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx-current.conf:/etc/nginx/nginx.conf:ro
      - ./certbot/conf:/etc/letsencrypt:ro
      - ./certbot/www:/var/www/certbot:ro
      - ./nginx/logs:/var/log/nginx:rw
      - nginx_cache:/var/cache/nginx:rw
    networks:
      - app-network
    depends_on:
      app:
        condition: service_healthy
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 256M
        reservations:
          cpus: '0.1'
          memory: 64M
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:80/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    command: "/bin/sh -c 'while :; do sleep 6h & wait $${!}; nginx -s reload; done & nginx -g \"daemon off;\"'"

  certbot:
    image: certbot/certbot:latest
    container_name: 1001-stories-certbot
    restart: unless-stopped
    volumes:
      - ./certbot/conf:/etc/letsencrypt:rw
      - ./certbot/www:/var/www/certbot:rw
      - ./certbot/logs:/var/log/letsencrypt:rw
    networks:
      - app-network
    deploy:
      resources:
        limits:
          cpus: '0.25'
          memory: 128M
        reservations:
          cpus: '0.05'
          memory: 32M
    logging:
      driver: "json-file"
      options:
        max-size: "5m"
        max-file: "2"
    entrypoint: |
      /bin/sh -c '
        # Check if SSL certificates exist
        if [ ! -d "/etc/letsencrypt/live/1001stories.seedsofempowerment.org" ]; then
          echo "⚠️  No SSL certificates found!"
          echo ""
          echo "Initial certificate generation required. Please run:"
          echo "  docker compose run --rm --entrypoint /bin/sh certbot -c \"certbot certonly --webroot -w /var/www/certbot -d 1001stories.seedsofempowerment.org --email noreply@1001stories.org --agree-tos --non-interactive\""
          echo ""
          echo "Or use the SSL setup script: ./scripts/setup-ssl.sh"
          exit 1
        fi

        echo "✅ SSL certificates found. Starting renewal daemon..."
        trap exit TERM
        while :; do
          certbot renew --webroot -w /var/www/certbot --quiet
          sleep 12h & wait $${!}
        done
      '

  # Prometheus for monitoring (lightweight setup)
  prometheus:
    image: prom/prometheus:latest
    container_name: 1001-stories-prometheus
    restart: unless-stopped
    # ports:
      # - "9090:9090"  # SECURITY: Prometheus metrics secured - access via nginx proxy only
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus_data:/prometheus:rw
    networks:
      - app-network
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.1'
          memory: 128M
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/usr/share/prometheus/console_libraries'
      - '--web.console.templates=/usr/share/prometheus/consoles'
      - '--storage.tsdb.retention.time=15d'
      - '--storage.tsdb.retention.size=2GB'
      - '--web.enable-lifecycle'
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "2"

  # Node exporter for system metrics
  node-exporter:
    image: prom/node-exporter:latest
    container_name: 1001-stories-node-exporter
    restart: unless-stopped
    # ports:
      # - "9100:9100"  # SECURITY: Node exporter secured - access via nginx proxy only
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
    command:
      - '--path.procfs=/host/proc'
      - '--path.rootfs=/rootfs'
      - '--path.sysfs=/host/sys'
      - '--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)'
    networks:
      - app-network
    deploy:
      resources:
        limits:
          cpus: '0.25'
          memory: 128M
        reservations:
          cpus: '0.05'
          memory: 32M
    logging:
      driver: "json-file"
      options:
        max-size: "5m"
        max-file: "2"

networks:
  app-network:
    driver: bridge
    driver_opts:
      com.docker.network.bridge.name: br-1001stories
    ipam:
      config:
        - subnet: 172.20.0.0/16

volumes:
  postgres_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /opt/1001-stories/data/postgres
  redis_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /opt/1001-stories/data/redis
  prometheus_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /opt/1001-stories/data/prometheus
  nginx_cache:
    driver: local