# Production Docker Compose with Auto-scaling Support
# 1001 Stories Educational Platform
# Optimized for cost-efficiency and high availability

version: '3.8'

services:
  # Load Balancer (HAProxy for multi-instance support)
  loadbalancer:
    image: haproxy:alpine
    container_name: 1001-stories-loadbalancer
    restart: unless-stopped
    ports:
      - "80:80"
      - "443:443"
      - "8404:8404"  # HAProxy stats
    volumes:
      - ./haproxy/haproxy.cfg:/usr/local/etc/haproxy/haproxy.cfg:ro
      - ./certbot/conf:/etc/letsencrypt:ro
      - ./certbot/www:/var/www/certbot:ro
    networks:
      - app-network
    depends_on:
      - app-1
      - app-2
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 256M
        reservations:
          cpus: '0.1'
          memory: 64M
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:8404/stats"]
      interval: 30s
      timeout: 10s
      retries: 3
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Application Instance 1 (Primary)
  app-1:
    build:
      context: .
      dockerfile: Dockerfile
      args:
        - BUILDKIT_INLINE_CACHE=1
    container_name: 1001-stories-app-1
    restart: unless-stopped
    env_file:
      - .env.production
    environment:
      - NODE_ENV=production
      - DATABASE_URL=postgresql://stories_user:${DB_PASSWORD}@pgbouncer:5432/stories_db
      - REDIS_URL=redis://:${REDIS_PASSWORD}@redis:6379
      - INSTANCE_ID=app-1
    volumes:
      - ./uploads:/app/uploads:rw
      - ./prisma:/app/prisma:ro
      - ./public/books:/app/public/books:ro
      - app_tmp_1:/tmp
    networks:
      - app-network
    depends_on:
      postgres:
        condition: service_healthy
      pgbouncer:
        condition: service_started
      redis:
        condition: service_healthy
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.25'
          memory: 256M
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:3000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Application Instance 2 (Secondary - for load distribution)
  app-2:
    build:
      context: .
      dockerfile: Dockerfile
      args:
        - BUILDKIT_INLINE_CACHE=1
    container_name: 1001-stories-app-2
    restart: unless-stopped
    env_file:
      - .env.production
    environment:
      - NODE_ENV=production
      - DATABASE_URL=postgresql://stories_user:${DB_PASSWORD}@pgbouncer:5432/stories_db
      - REDIS_URL=redis://:${REDIS_PASSWORD}@redis:6379
      - INSTANCE_ID=app-2
    volumes:
      - ./uploads:/app/uploads:rw
      - ./prisma:/app/prisma:ro
      - ./public/books:/app/public/books:ro
      - app_tmp_2:/tmp
    networks:
      - app-network
    depends_on:
      postgres:
        condition: service_healthy
      pgbouncer:
        condition: service_started
      redis:
        condition: service_healthy
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.25'
          memory: 256M
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:3000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    # Start as scaled-down instance (can be scaled up based on load)
    profiles:
      - scale-up

  # PostgreSQL with enhanced configuration
  postgres:
    image: postgres:15-alpine
    container_name: 1001-stories-postgres
    restart: unless-stopped
    environment:
      - POSTGRES_USER=stories_user
      - POSTGRES_PASSWORD=${DB_PASSWORD}
      - POSTGRES_DB=stories_db
      - PGDATA=/var/lib/postgresql/data/pgdata
      - POSTGRES_SHARED_PRELOAD_LIBRARIES=pg_stat_statements
      - POSTGRES_INITDB_ARGS=--data-checksums
    volumes:
      - postgres_data:/var/lib/postgresql/data:rw
      - ./postgres/postgresql.conf:/etc/postgresql/postgresql.conf:ro
      - ./postgres/init-scripts:/docker-entrypoint-initdb.d:ro
    networks:
      - app-network
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U stories_user -d stories_db"]
      interval: 10s
      timeout: 5s
      retries: 5
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    command: [
      "postgres",
      "-c", "config_file=/etc/postgresql/postgresql.conf",
      "-c", "log_statement=all",
      "-c", "log_destination=stderr",
      "-c", "logging_collector=off"
    ]

  # PgBouncer connection pooler
  pgbouncer:
    image: pgbouncer/pgbouncer:latest
    container_name: 1001-stories-pgbouncer
    restart: unless-stopped
    environment:
      - DATABASES_HOST=postgres
      - DATABASES_PORT=5432
      - DATABASES_USER=stories_user
      - DATABASES_PASSWORD=${DB_PASSWORD}
      - DATABASES_DBNAME=stories_db
      - POOL_MODE=transaction
      - SERVER_RESET_QUERY=DISCARD ALL
      - MAX_CLIENT_CONN=200
      - DEFAULT_POOL_SIZE=25
      - MIN_POOL_SIZE=10
      - RESERVE_POOL_SIZE=10
      - SERVER_LIFETIME=3600
      - SERVER_IDLE_TIMEOUT=600
    volumes:
      - ./postgres/pgbouncer.ini:/etc/pgbouncer/pgbouncer.ini:ro
      - ./postgres/userlist.txt:/etc/pgbouncer/userlist.txt:ro
    networks:
      - app-network
    depends_on:
      postgres:
        condition: service_healthy
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 256M
        reservations:
          cpus: '0.1'
          memory: 64M
    logging:
      driver: "json-file"
      options:
        max-size: "5m"
        max-file: "2"

  # Redis with persistence and memory optimization
  redis:
    image: redis:7-alpine
    container_name: 1001-stories-redis
    restart: unless-stopped
    command: [
      "redis-server",
      "--appendonly", "yes",
      "--requirepass", "${REDIS_PASSWORD}",
      "--maxmemory", "512mb",
      "--maxmemory-policy", "allkeys-lru",
      "--save", "900", "1",
      "--save", "300", "10",
      "--save", "60", "10000",
      "--tcp-keepalive", "300",
      "--timeout", "0"
    ]
    volumes:
      - redis_data:/data:rw
    networks:
      - app-network
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.1'
          memory: 128M
    healthcheck:
      test: ["CMD", "redis-cli", "--raw", "incr", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    logging:
      driver: "json-file"
      options:
        max-size: "5m"
        max-file: "2"

  # Prometheus monitoring
  prometheus:
    image: prom/prometheus:latest
    container_name: 1001-stories-prometheus
    restart: unless-stopped
    # ports:
      # - "9090:9090"  # SECURITY: Prometheus metrics secured - access via nginx proxy only
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus_data:/prometheus:rw
    networks:
      - app-network
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.1'
          memory: 128M
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/usr/share/prometheus/console_libraries'
      - '--web.console.templates=/usr/share/prometheus/consoles'
      - '--storage.tsdb.retention.time=15d'
      - '--web.enable-lifecycle'
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "2"

  # Node exporter for system metrics
  node-exporter:
    image: prom/node-exporter:latest
    container_name: 1001-stories-node-exporter
    restart: unless-stopped
    # ports:
      # - "9100:9100"  # SECURITY: Node exporter secured - access via nginx proxy only
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
    command:
      - '--path.procfs=/host/proc'
      - '--path.rootfs=/rootfs'
      - '--path.sysfs=/host/sys'
      - '--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)'
    networks:
      - app-network
    deploy:
      resources:
        limits:
          cpus: '0.25'
          memory: 128M
        reservations:
          cpus: '0.05'
          memory: 32M
    logging:
      driver: "json-file"
      options:
        max-size: "5m"
        max-file: "2"

  # Grafana for monitoring dashboards (optional)
  grafana:
    image: grafana/grafana-oss:latest
    container_name: 1001-stories-grafana
    restart: unless-stopped
    # ports:
      # - "3001:3000"  # SECURITY: Grafana secured - access via nginx proxy only
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_ADMIN_PASSWORD}
      - GF_USERS_ALLOW_SIGN_UP=false
      - GF_INSTALL_PLUGINS=grafana-piechart-panel
    volumes:
      - grafana_data:/var/lib/grafana:rw
      - ./monitoring/grafana/provisioning:/etc/grafana/provisioning:ro
    networks:
      - app-network
    depends_on:
      - prometheus
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 256M
        reservations:
          cpus: '0.1'
          memory: 64M
    profiles:
      - monitoring
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "2"

  # Automatic SSL certificate renewal
  certbot:
    image: certbot/certbot:latest
    container_name: 1001-stories-certbot
    restart: unless-stopped
    volumes:
      - ./certbot/conf:/etc/letsencrypt:rw
      - ./certbot/www:/var/www/certbot:rw
      - ./certbot/logs:/var/log/letsencrypt:rw
    networks:
      - app-network
    deploy:
      resources:
        limits:
          cpus: '0.25'
          memory: 128M
        reservations:
          cpus: '0.05'
          memory: 32M
    logging:
      driver: "json-file"
      options:
        max-size: "5m"
        max-file: "2"
    entrypoint: "/bin/sh -c 'trap exit TERM; while :; do certbot renew --webroot -w /var/www/certbot --quiet; sleep 12h & wait $${!}; done;'"

networks:
  app-network:
    driver: bridge
    driver_opts:
      com.docker.network.bridge.name: br-1001stories-prod
    ipam:
      config:
        - subnet: 172.21.0.0/16

volumes:
  postgres_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /opt/1001-stories/data/postgres
  redis_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /opt/1001-stories/data/redis
  prometheus_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /opt/1001-stories/data/prometheus
  grafana_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /opt/1001-stories/data/grafana
  app_tmp_1:
    driver: tmpfs
    driver_opts:
      tmpfs-size: 100m
      tmpfs-mode: 1777
  app_tmp_2:
    driver: tmpfs
    driver_opts:
      tmpfs-size: 100m
      tmpfs-mode: 1777